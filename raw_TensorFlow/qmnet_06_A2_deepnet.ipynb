{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import qctoolkit as qtk\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from horton import GOBasisFamily\n",
    "#basis = GOBasisFamily('basis', filename='basis/sto2g/H_Ne_uncontracted.nwchem')\n",
    "#basis = '3-21g'\n",
    "#basis = 'sto-3g'\n",
    "#basis = GOBasisFamily('H_He_basis', filename='basis/sto6g/H_Ne.nwchem')\n",
    "basis = GOBasisFamily('H_He_basis', filename='basis/sto6g/H_Be-s.nwchem')\n",
    "\n",
    "resolution = 0.002\n",
    "batch_size = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "molstr_list = [\n",
    "    'HH',\n",
    "    'HHe+',\n",
    "    'HLi',\n",
    "    'HBe+',\n",
    "#     'HeHe',\n",
    "#     'HeLi+',\n",
    "#     'HeBe',\n",
    "#     'LiLi',\n",
    "#     'LiBe+',\n",
    "#     'BeBe',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2_4.0 finished\n",
      "H1He1_4.0 finished\n",
      "H1Li1_4.0 finished\n",
      "H1Be1_4.0 finished\n",
      "[1851, 1851, 1851, 1407]\n"
     ]
    }
   ],
   "source": [
    "inp_grp = []\n",
    "#inp_dump = []\n",
    "for molstr in molstr_list:\n",
    "    if '+' in molstr:\n",
    "        charge = 1\n",
    "    elif '-' in molstr:\n",
    "        charge = -1\n",
    "    else:\n",
    "        charge = 0\n",
    "    alist = re.findall('[A-Z][a-z]*', molstr)\n",
    "    Zs = [qtk.n2Z(a) for a in alist]\n",
    "    inp_list = []\n",
    "    inp_grp.append(inp_list)\n",
    "    #inp_dump.append(inp_list)\n",
    "    res = resolution\n",
    "    for R in np.arange(0.3, 4.0 + res, res):\n",
    "        mol = qtk.Molecule()\n",
    "        ZR = [[Zs[0], 0,0,0], [Zs[1], R, 0, 0]]\n",
    "        mol.build(ZR)\n",
    "        mol.charge = charge\n",
    "        mol.name = mol.name + '_%s' % str(R)\n",
    "        inp = qtk.QMInp(mol, program='horton', basis_set=basis, scf_step=30)\n",
    "        try:\n",
    "            inp.run()\n",
    "            D, U = np.linalg.eigh(inp.olp)\n",
    "            inp.X = U / np.sqrt(D)\n",
    "            \n",
    "            # to save inps into pickle file\n",
    "            #inp.delete_ht_types()\n",
    "            #inp.delete_matrices()\n",
    "            \n",
    "            inp_list.append(inp)\n",
    "        except:\n",
    "            pass\n",
    "    print \"%s finished\" % mol.name\n",
    "print [len(inp) for inp in inp_grp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe747b2a2d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndeMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe747b2ad50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(inp_grp)):\n",
    "    inp = inp_grp[i]\n",
    "    E = np.array([o.Et for o in inp])\n",
    "    E = E-E[-1]\n",
    "    #print E\n",
    "    plt.plot(E, label=molstr_list[i])\n",
    "plt.ylim(-0.35, 0.001)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.673868062839\n",
      "-0.673868062839\n"
     ]
    }
   ],
   "source": [
    "# Numpy version implementation\n",
    "\n",
    "def get_input_tensor(mol):\n",
    "    \"\"\"Extract matrices and pack as tensor\"\"\"\n",
    "    S, K, Na, C0, X, Er = mol.olp, mol.kin, mol.na, mol.initial_mov, mol.X, mol.er\n",
    "    Er_j = np.diagonal(np.diagonal(er))\n",
    "\n",
    "    Er_x = np.diagonal(np.diagonal(er, axis1=0, axis2=2), axis1=1, axis2=0)\n",
    "    I = np.stack([S, K, Na, Er_j, Er_x, C0, X])\n",
    "    nn = mol.ht_external['nn']\n",
    "    occ = mol.ht_exp_alpha.occupations\n",
    "    return I, Er, occ, nn\n",
    "    \n",
    "def get_output(I, Er, occ, nn, C):\n",
    "    \"\"\"take input tensor and approximated MO coefficients, C, to compute total energy\"\"\"\n",
    "    K = I[1]\n",
    "    Na = I[2]\n",
    "    dm = (C * occ).dot(C.T)\n",
    "    \n",
    "    Ek = np.trace(dm.dot(K)) * 2\n",
    "    Ev = np.trace(dm.dot(Na)) * 2\n",
    "    Ej = np.trace(dm.dot(np.tensordot(dm, Er, axes=([0,1], [0,2])))) * 2\n",
    "    Ex = -np.trace(dm.dot(np.tensordot(dm, Er, axes=([0,1], [0,1]))))\n",
    "    E_tot = np.sum([Ek, Ev, Ej, Ex, nn])\n",
    "    return E_tot\n",
    "\n",
    "inp = inp_grp[0][5]\n",
    "I_np, Er_np, occ, nn = get_input_tensor(inp)\n",
    "C = inp.ht_exp_alpha.coeffs.__array__()\n",
    "print get_output(I_np, Er_np, occ, nn, C)\n",
    "print inp.Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_valid(valid_ind, train_inds=None, random_seed=0):\n",
    "    if valid_ind >= len(inp_grp):\n",
    "        valid_ind = len(inp_grp) - 1\n",
    "    print \"%s is used as validation molecule\" % molstr_list[valid_ind]\n",
    "    inp_valid = inp_grp[valid_ind]\n",
    "    if valid_ind > 0:\n",
    "        if train_inds is None: train_inds = range(len(inp_grp))\n",
    "        inps_all = list(qtk.flatten([inp_grp[i] for i in train_inds if i != valid_ind]))\n",
    "    else:\n",
    "        inps_all = list(qtk.flatten(inp_grp))\n",
    "    inp_train, inp_test = train_test_split(inps_all, random_state=random_seed, test_size=0.1)\n",
    "    return inp_train, inp_test, inp_valid\n",
    "\n",
    "def validation_inds(inp_valid):\n",
    "    E = np.array([inp.Et for inp in inp_valid])\n",
    "    ind_min = np.argmin(E)\n",
    "    ind_max = len(E) - 1\n",
    "    ind_mid = ind_min + (ind_max - ind_min) / 2\n",
    "    ind_rep = ind_min / 2\n",
    "    return ind_rep, ind_min, ind_mid, ind_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfIO(mol_list, inds=None):\n",
    "    I_list, Er_list, occ_list, nn_list, C_list, labels = [[] for _ in range(6)]\n",
    "    \n",
    "    if inds is None:\n",
    "        inds = range(len(mol_list))\n",
    "        \n",
    "    for i in inds:\n",
    "        mol = mol_list[i]\n",
    "        C = mol.ht_exp_alpha.coeffs.__array__()\n",
    "        C_list.append(C)\n",
    "        I, Er, occ, nn = get_input_tensor(mol)\n",
    "        I_list.append(I)\n",
    "        Er_list.append(Er)\n",
    "        occ_list.append(occ)\n",
    "        nn_list.append(nn)\n",
    "        labels.append(get_output(I, Er, occ, nn, C))\n",
    "        \n",
    "    return np.stack(I_list).astype(np.float64), np.stack(Er_list).astype(np.float64), \\\n",
    "           np.stack(occ_list).astype(np.float64), np.stack(nn_list).astype(np.float64), \\\n",
    "           np.stack(C_list).astype(np.float64), np.stack(labels).astype(np.float64)\n",
    "\n",
    "def tfIO_batch(mol_list, batch_size, inds=None):\n",
    "    \n",
    "    def batches(mol_list):\n",
    "        for i in range(0, len(mol_list), batch_size):\n",
    "            yield mol_list[i:i + batch_size]\n",
    "\n",
    "    I, Er, occ, nn, C, y = [], [], [], [], [], []\n",
    "    if inds is None:\n",
    "        for mol_batch in batches(mol_list):\n",
    "            I_b, Er_b, occ_b, nn_b, C_b, y_b = tfIO(mol_batch)\n",
    "            I.append(I_b)\n",
    "            Er.append(Er_b)\n",
    "            occ.append(occ_b)\n",
    "            nn.append(nn_b)\n",
    "            C.append(C_b)\n",
    "            y.append(y_b)\n",
    "    else:\n",
    "        I_b, Er_b, occ_b, nn_b, C_b, y_b = tfIO(mol_list, inds)\n",
    "        I.append(I_b)\n",
    "        Er.append(Er_b)\n",
    "        occ.append(occ_b)\n",
    "        nn.append(nn_b)\n",
    "        C.append(C_b)\n",
    "        y.append(y_b)\n",
    "    return I, Er, occ, nn, C, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HH is used as validation molecule\n"
     ]
    }
   ],
   "source": [
    "inp_train, inp_test, inp_valid = train_test_valid(0, [0])\n",
    "# print len(inp_train), len(inp_test), len(inp_valid)\n",
    "I_train, Er_train, occ_train, nn_train, C_train, y_train = tfIO_batch(inp_train, batch_size)\n",
    "I_test, Er_test, occ_test, nn_test, C_test, y_test = tfIO_batch(inp_test, batch_size)\n",
    "I_valid, Er_valid, occ_valid, nn_valid, C_valid, y_valid = tfIO_batch(inp_valid, batch_size)\n",
    "\n",
    "I_valid2, Er_valid2, occ_valid2, nn_valid2, C_valid2, y_valid2 = tfIO(inp_valid, [1,3,5])\n",
    "# print I_valid2.shape\n",
    "# print I_test[0].shape\n",
    "# print I_train[0].shape\n",
    "# print validation_inds(inp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  3.09180307e-05  -6.68852249e-01  -1.20869590e+00  -2.22022629e-01]\n",
      "  [ -1.22619998e-02  -4.12670442e-01   1.31337528e+00   3.21825977e-01]\n",
      "  [ -8.71836997e-01   2.47230869e-02  -1.41565503e-01   1.08173331e+00]\n",
      "  [ -1.72151779e-01   1.60947199e-02   8.91996221e-02  -1.39923248e+00]]\n",
      "\n",
      " [[ -1.34752765e-01  -6.75599815e-01  -1.20579693e+00  -1.22658815e-01]\n",
      "  [ -1.09823526e-02  -5.20783054e-01   1.51222466e+00  -4.59265135e-01]\n",
      "  [ -8.70057481e-01   2.78158018e-01   4.16904167e-02  -1.10193471e+00]\n",
      "  [ -1.20130390e-01   2.45902515e-01  -3.72567766e-01   1.68859796e+00]]\n",
      "\n",
      " [[ -1.47039071e-03   3.75916506e-01   1.71966339e-01   1.33843257e+00]\n",
      "  [  4.30587154e-03   5.79397337e-01   3.69022673e-01  -1.25695663e+00]\n",
      "  [ -9.94676817e-01  -9.59666778e-02   2.48809320e-01  -2.50496483e-02]\n",
      "  [ -2.18641880e-02   3.48142883e-01  -9.90874997e-01   1.55368331e-01]]\n",
      "\n",
      " ..., \n",
      " [[ -1.04730125e-03  -3.17969956e-01  -4.23817893e-01   1.29522123e+00]\n",
      "  [  2.48489944e-03  -3.41175871e-01  -4.49354098e-01  -1.30225085e+00]\n",
      "  [ -9.95878222e-01   2.05846652e-01  -1.89277159e-01  -3.09327673e-02]\n",
      "  [ -1.58405024e-02  -7.49282018e-01   7.23298267e-01   1.71331022e-01]]\n",
      "\n",
      " [[ -7.07250611e-04   6.68718327e-01   1.20923383e+00  -2.07529703e-01]\n",
      "  [  1.02808389e-02   4.12446166e-01  -1.31390823e+00   2.90307668e-01]\n",
      "  [  8.71767994e-01  -1.94177687e-02   1.31186140e-01   1.08167024e+00]\n",
      "  [  1.72568647e-01  -1.20994195e-02  -9.34859312e-02  -1.39286577e+00]]\n",
      "\n",
      " [[ -3.52322967e-01  -3.55194481e-01   9.30334865e-01  -9.40415520e-01]\n",
      "  [ -3.22699509e-01  -6.04369552e-01  -1.20615738e+00   7.87176561e-01]\n",
      "  [ -3.52322967e-01   3.55194481e-01  -9.30334865e-01  -9.40415520e-01]\n",
      "  [ -3.22699509e-01   6.04369552e-01   1.20615738e+00   7.87176561e-01]]]\n",
      "stack.shape:  (696, 4, 4, 4)\n",
      "f_input_flatten.shape:  (696, 96)\n",
      "Wh.shape:  (96, 16)\n",
      "(696, 5, 4, 4)\n",
      "(696, 4, 4)\n",
      "C_orth_init.shape (696, 4, 4)\n",
      "1.38300482178e-12\n",
      "stack.shape:  (696, 4, 4, 4)\n",
      "f_input_flatten.shape:  (696, 96)\n",
      "Wh.shape:  (96, 16)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def lrelu(x, alpha):\n",
    "    return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n",
    "\n",
    "def flatten(x_tensor):\n",
    "    \n",
    "    if type(x_tensor) is np.ndarray:\n",
    "        shape = x_tensor.shape\n",
    "    else:\n",
    "        shape = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    flatten_shape = np.prod(shape[1:])\n",
    "    \n",
    "    return tf.reshape(x_tensor, [-1, flatten_shape])\n",
    "\n",
    "def hidden_layer(I, C_prd=None, Whp=None, bhp=None, Whn=None, bhn=None, keep_prob=1.0, sess=None):\n",
    "    \n",
    "    if C_prd is None:\n",
    "        C_prd = I[:,-2]\n",
    "        shape = C_prd.shape[-2:]\n",
    "    else:    \n",
    "        shape = C_prd.get_shape()[-2:]\n",
    "        \n",
    "    S, K, V, Er_j, Er_x = (I[:,i] for i in range(5))\n",
    "    \n",
    "    shape_product = int(S.shape[1] * S.shape[2])\n",
    "    f_input_flatten = flatten(tf.stack((S, K, V, Er_j, Er_x,C_prd), axis=1))\n",
    "    \n",
    "    return_Whp = False\n",
    "    if Whp is None:\n",
    "        return_Whp = True\n",
    "        Whp = tf.Variable(tf.truncated_normal(\n",
    "            (f_input_flatten.get_shape().as_list()[-1], shape_product),\n",
    "            dtype=tf.float64\n",
    "        ), dtype=tf.float64, name='weights_hp')\n",
    "\n",
    "        bhp = tf.Variable(tf.zeros(shape_product, dtype=tf.float64), dtype=tf.float64, name='biases_hp')\n",
    "\n",
    "        Whn = tf.Variable(tf.truncated_normal(\n",
    "            (f_input_flatten.get_shape().as_list()[-1], shape_product),\n",
    "            dtype=tf.float64\n",
    "        ), dtype=tf.float64, name='weights_hn')\n",
    "\n",
    "        bhn = tf.Variable(tf.zeros(shape_product, dtype=tf.float64), dtype=tf.float64, name='biases_hn')\n",
    "    \n",
    "    if sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print 'stack.shape: ', str(sess.run(tf.stack((S, K, V, C_prd), axis=1)).shape)\n",
    "        print 'f_input_flatten.shape: ', str(sess.run(f_input_flatten).shape)\n",
    "        print 'Wh.shape: ', str(sess.run(Whn).shape)\n",
    "    # returning ReLU(WX + b)\n",
    "    C_new_flatten_p = lrelu(tf.add(tf.matmul( f_input_flatten, Whp), bhp), 0.1)\n",
    "    C_new_flatten_n = lrelu(tf.add(tf.matmul(-f_input_flatten, Whn), bhn), 0.1)\n",
    "    \n",
    "    C_added = tf.layers.dropout(tf.add(C_new_flatten_p, C_new_flatten_n), keep_prob)\n",
    "    \n",
    "    C_new = tf.reshape(C_added , [-1, tf.shape(C_prd)[1], tf.shape(C_prd)[2]])\n",
    "    \n",
    "    return C_new, Whp, bhp, Whn, bhn\n",
    "    \n",
    "def normailization_layer(I, C_prd, sess=None):\n",
    "\n",
    "    C_sym = tf.matmul(tf.transpose(C_prd, perm=[0,2,1]), C_prd)\n",
    "\n",
    "    _, C_diag = tf.self_adjoint_eig(C_sym)\n",
    "    \n",
    "    return tf.matmul(I[:,-1], C_diag)\n",
    "\n",
    "def output_layer(I, Er, occ, nn, C_prd, sess=None):\n",
    "    K, Na = I[:,1], I[:,2]\n",
    "    \n",
    "    batch = tf.shape(I)[0]\n",
    "    C_occ = tf.multiply(tf.expand_dims(occ, 1), C_prd)\n",
    "    dm = tf.matmul(C_occ, tf.transpose(C_prd, perm=[0,2,1]))\n",
    "    \n",
    "    ind = tf.transpose(tf.stack([tf.range(batch), tf.range(batch)]))\n",
    "    J_kernel = tf.gather_nd(tf.tensordot(dm, Er, axes=([1,2], [1,3])), ind)\n",
    "    X_kernel = tf.gather_nd(tf.tensordot(dm, Er, axes=([1,2], [1,2])), ind)\n",
    "    \n",
    "    Ek = tf.trace(tf.matmul(dm, K)) * 2\n",
    "    Ev = tf.trace(tf.matmul(dm, Na)) * 2\n",
    "    Ej = tf.trace(tf.matmul(dm, J_kernel)) * 2\n",
    "    Ex = -tf.trace(tf.matmul(dm, X_kernel))\n",
    "    \n",
    "    E_total = tf.add(Ek, Ev)\n",
    "    E_total = tf.add(E_total, Ej)\n",
    "    E_total = tf.add(E_total, Ex)\n",
    "    E_total = tf.add(E_total, nn)\n",
    "    \n",
    "    return E_total\n",
    "    \n",
    "# test\n",
    "_N = 20\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print C_test[0]\n",
    "    E = output_layer(I_test[0], Er_test[0], occ_test[0], nn_test[0], C_test[0], sess)\n",
    "    hidden_out = sess.run(hidden_layer(I_test[0], sess=sess))\n",
    "    C_sess = hidden_out[0]\n",
    "    print I_test[0].shape\n",
    "    print C_sess.shape\n",
    "    C_orth_init = sess.run(normailization_layer(I_test[0], C_sess, sess))\n",
    "    print 'C_orth_init.shape',\n",
    "    print C_orth_init.shape\n",
    "    print abs(sess.run(E) -y_test[0]).sum()\n",
    "with tf.Session() as sess:\n",
    "    C_hidden_test = hidden_layer(I_test[0], sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(root_name='model', learn_rate_min=0.0001, valid_ind=2, \n",
    "          train_list=range(len(inp_grp)), print_step=5,\n",
    "          threshold=1E-5, maxiter=100000, from_scratch=False,\n",
    "          learn_rate_steps=50, learn_rate_start=0.1, learn_rate_base=0.5,\n",
    "          batch_size=batch_size, random_seed=0\n",
    "         ):\n",
    "    \n",
    "    def log_msg(msg, output=True):\n",
    "        log.write(msg)\n",
    "        log.flush()\n",
    "        if output:\n",
    "            print msg\n",
    "    \n",
    "    inp_train, inp_test, inp_valid = train_test_valid(valid_ind, train_list, random_seed)\n",
    "    print \"train/test/validation size: %d/%d/%d\" % (len(inp_train), len(inp_test), len(inp_valid))\n",
    "    I_train, Er_train, occ_train, nn_train, C_train, y_train = tfIO_batch(inp_train, batch_size)\n",
    "    I_test, Er_test, occ_test, nn_test, C_test, y_test = tfIO_batch(inp_test, batch_size)\n",
    "    I_valid, Er_valid, occ_valid, nn_valid, C_valid, y_valid = tfIO_batch(inp_valid, batch_size)\n",
    "    i_rep, i_min, i_mid, i_max = validation_inds(inp_valid)\n",
    "    v_inds = [i_rep, i_min, i_mid, i_max]\n",
    "    I_valid2, Er_valid2, occ_valid2, nn_valid2, C_valid2, y_valid2 = tfIO(inp_valid, inds=v_inds)\n",
    "    \n",
    "    status = \"root name: \" + root_name + \"\\n\"\n",
    "    status += \"batch size: \" + str(I_train[0].shape[0]) + \"\\n\"\n",
    "    status += \"number of batches: \" + str(len(I_train)) + \"\\n\"\n",
    "    status += \"training set: \" + str([molstr_list[i] for i in train_list]) + \"\\n\"\n",
    "    status += \"validation: \" + molstr_list[valid_ind] + \"\\n\"\n",
    "    status += \"learning rate min: \" + str(learn_rate_min) + \"\\n\"\n",
    "    status += \"learning rate steps: \" + str(learn_rate_steps) + \"\\n\"\n",
    "    status += \"learning rate start: \" + str(learn_rate_start) + \"\\n\"\n",
    "    status += \"learning rate base: \" + str(learn_rate_base) + \"\\n\"\n",
    "    status += \"print step: \" + str(print_step) + \"\\n\"\n",
    "    status += \"threshold: \" + str(threshold) + \"\\n\"\n",
    "    status += \"maxiter: \" + str(maxiter) + \"\\n\"\n",
    "    status += \"execuate time: \" + datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\") + \"\\n\\n\"\n",
    "    \n",
    "    log = open(\"%s.log\" % root_name, 'w')\n",
    "    log_msg(status)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    def get_shape(tensor):\n",
    "        shape = list(tensor.shape)\n",
    "        shape.insert(0, None)\n",
    "        return shape\n",
    "\n",
    "    # input tensors\n",
    "    I = tf.placeholder(tf.float64, shape=get_shape(I_test[0][0]), name='I')\n",
    "    Er = tf.placeholder(tf.float64, shape=get_shape(Er_test[0][0]), name='Er')\n",
    "    occ = tf.placeholder(tf.float64, shape=get_shape(occ_test[0][0]), name='occ')\n",
    "    nn = tf.placeholder(tf.float64, shape=get_shape(nn_test[0][0]), name='nn')\n",
    "    keep_prob = tf.placeholder(tf.float64, name='keep_prob')\n",
    "\n",
    "    # training tensors\n",
    "    y = tf.placeholder(tf.float64, shape=get_shape(y_test[0][0]), name='y')\n",
    "\n",
    "#     # network architecture\n",
    "#     C_prd = hidden_layer(I)[0]\n",
    "#     for _ in range(1):\n",
    "#         C_prd = hidden_layer(I, C_prd)[0]\n",
    "#     C_prd = normailization_layer(I, C_prd)\n",
    "#     #C_prd = normailization_layer(I, C_prd)\n",
    "#     y_prd = output_layer(I, Er, occ, nn, C_prd)\n",
    "    \n",
    "    # network architecture\n",
    "    C_prd, Wp, bp, Wn, bn = hidden_layer(I)\n",
    "    #C_prd = hidden_layer(I, C_prd, Wp, bp, Wn, bn, keep_prob=keep_prob)[0]\n",
    "    for _ in range(4):\n",
    "        C_prd, Wp, bp, Wn, bn = hidden_layer(I, C_prd)\n",
    "#     C_prd, Wp, bp, Wn, bn = hidden_layer(I, C_prd)\n",
    "    #C_prd = hidden_layer(I, C_prd, Wp, bp, Wn, bn, keep_prob=keep_prob)[0]\n",
    "    for _ in range(2):\n",
    "        C_prd = hidden_layer(I, C_prd, Wp, bp, Wn, bn)[0]\n",
    "    C_prd, Wp, bp, Wn, bn = hidden_layer(I, C_prd)\n",
    "    #C_prd = hidden_layer(I, C_prd, Wp, bp, Wn, bn, keep_prob=keep_prob)[0]\n",
    "    for _ in range(2):\n",
    "        C_prd = hidden_layer(I, C_prd, Wp, bp, Wn, bn)[0]\n",
    "    C_prd = hidden_layer(I, C_prd)[0]\n",
    "    C_prd = normailization_layer(I, C_prd)\n",
    "    y_prd = output_layer(I, Er, occ, nn, C_prd)\n",
    "\n",
    "    # network output\n",
    "    C_out = C_prd\n",
    "    #err = tf.pow(y - y_prd, 2)\n",
    "    #err = tf.metrics.mean_squared_error(y, y_prd)\n",
    "    err = tf.reduce_mean(tf.pow(y - y_prd, 2))\n",
    "\n",
    "    # add C_prd_iteration history for post processing on the learning of the following properties\n",
    "    # 1. density difference\n",
    "    # 2. force\n",
    "    # 3. dipole moment\n",
    "    # 4. HOMO-LUMO gap\n",
    "\n",
    "    n_epoch = tf.Variable(0, trainable=False)\n",
    "    learn_rate = tf.maximum(tf.train.exponential_decay(\n",
    "                                learn_rate_start, n_epoch, learn_rate_steps, learn_rate_base),\n",
    "                            learn_rate_min\n",
    "                           )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(err) # default learning rate 0.001\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(err) \n",
    "    saver = tf.train.Saver()\n",
    "    save_path = \"%s.ckpt\" % root_name\n",
    "\n",
    "    #with tf.Session() as sess:\n",
    "    sess = tf.Session()\n",
    "    try:\n",
    "        train_err_hist = []\n",
    "        test_err_hist = []\n",
    "        valid_err_hist = []\n",
    "        C_valid_hist = []\n",
    "        C_test_hist = []\n",
    "        learn_rate_hist = []\n",
    "\n",
    "        if not from_scratch:\n",
    "            try:\n",
    "                saver.restore(sess, save_path)\n",
    "                train_err_hist, test_err_hist, valid_err_hist, C_valid_hist, C_test_hist, learn_rate_hist = \\\n",
    "                qtk.load('%s_hist.pkl' % root_name)\n",
    "                msg = 'model and history loaded, continue optimizing'\n",
    "            except:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                msg = 'no model found, or reload failed, start from scratch'\n",
    "        else:\n",
    "            msg = 'start from scratch...'\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        log_msg(msg + \"\\n\")\n",
    "        test_err = 1\n",
    "        epoch = len(test_err_hist)\n",
    "        while test_err > threshold and epoch < maxiter:\n",
    "        #for opt_itr in range(200):\n",
    "\n",
    "            train_err_list = []\n",
    "            for I_b, Er_b, occ_b, nn_b, C_b, y_b in zip(I_train, Er_train, occ_train, nn_train, C_train, y_train):\n",
    "                train_dict = {I:I_b, Er:Er_b, occ:occ_b, nn:nn_b, y:y_b, keep_prob:0.8, n_epoch:epoch}\n",
    "                sess.run(optimizer, feed_dict=train_dict)\n",
    "                #train_err_list.append(np.array(sess.run(err, feed_dict=train_dict)))\n",
    "                train_err_list.append(sess.run(err, feed_dict=train_dict))\n",
    "            #train_err = np.concatenate(train_err_list).mean()\n",
    "            train_err = np.array(train_err_list).mean()\n",
    "            train_err_hist.append(train_err)\n",
    "            current_learn_rate = sess.run(learn_rate, feed_dict=train_dict)\n",
    "            learn_rate_hist.append(current_learn_rate)\n",
    "\n",
    "            test_err_list = []\n",
    "            for I_t, Er_t, occ_t, nn_t, C_t, y_t in zip(I_test, Er_test, occ_test, nn_test, C_test, y_test):\n",
    "                test_dict = {I:I_t, Er:Er_t, occ:occ_t, nn:nn_t, y:y_t, keep_prob:1.0}\n",
    "                #test_err_list.append(np.array(sess.run(err, feed_dict=test_dict)))\n",
    "                test_err_list.append(sess.run(err, feed_dict=test_dict))\n",
    "            #test_err = np.concatenate(test_err_list).mean()\n",
    "            test_err = np.array(test_err_list).mean()\n",
    "            test_err_hist.append(test_err)\n",
    "            \n",
    "            test2_dict = {\n",
    "                I:I_test[0][:3], \n",
    "                Er:Er_test[0][:3], \n",
    "                occ:occ_test[0][:3], \n",
    "                nn:nn_test[0][:3], \n",
    "                y:y_test[0][:3],\n",
    "                keep_prob:1.0\n",
    "            }\n",
    "            C_test_hist.append(np.array(sess.run(C_out, feed_dict=test2_dict)))\n",
    "\n",
    "            valid_err_list = []\n",
    "            for I_v, Er_v, occ_v, nn_v, C_v, y_v in zip(I_valid, Er_valid, occ_valid, nn_valid, C_valid, y_valid):\n",
    "                valid_dict = {I:I_v, Er:Er_v, occ:occ_v, nn:nn_v, y:y_v, keep_prob:1.0}\n",
    "                #valid_err_list.append(np.array(sess.run(err, feed_dict=valid_dict)))\n",
    "                valid_err_list.append(sess.run(err, feed_dict=valid_dict))\n",
    "            #valid_err = np.concatenate(valid_err_list).mean()\n",
    "            valid_err = np.array(valid_err_list).mean()\n",
    "            valid_err_hist.append(valid_err)\n",
    "            \n",
    "            valid2_dict = {I:I_valid2, Er:Er_valid2, occ:occ_valid2, nn:nn_valid2, y:y_valid2}\n",
    "            C_valid_hist.append(np.array(sess.run(C_out, feed_dict=valid2_dict)))\n",
    "\n",
    "            epoch = len(test_err_hist)\n",
    "            msg = \"epoch: %5d train/test/validatoin error: %f/%f/%f at rate %f\" % \\\n",
    "            (epoch, train_err, test_err, valid_err, current_learn_rate)\n",
    "            \n",
    "            log_msg(msg + \"\\n\", False)\n",
    "            \n",
    "            #epoch += 1\n",
    "            \n",
    "            if epoch % print_step == 0:\n",
    "                print msg\n",
    "                qtk.save([train_err_hist, test_err_hist, valid_err_hist, C_valid_hist, C_test_hist], \n",
    "                         \"%s_hist.pkl\" % root_name)\n",
    "                \n",
    "        save_path_out = saver.save(sess, save_path)\n",
    "        msg = \"Model saved in file: %s\" % save_path_out\n",
    "        log_msg(msg + \"\\n\")\n",
    "        qtk.save([train_err_hist, test_err_hist, valid_err_hist, C_valid_hist, C_test_hist, learn_rate_hist], \n",
    "                 \"%s_hist.pkl\" % root_name)\n",
    "        print \"optimization history saved\"\n",
    "        log.close()\n",
    "        sess.close()\n",
    "        print \"session and log file closed\"\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        new_msg = \"keyboard interrupt, current stage: %s\" % msg\n",
    "        log_msg(new_msg + \"\\n\")\n",
    "        save_path_out = saver.save(sess, save_path)\n",
    "        msg = \"Model saved in file: %s\" % save_path_out\n",
    "        log_msg(msg + \"\\n\")\n",
    "        qtk.save([train_err_hist, test_err_hist, valid_err_hist, C_valid_hist, C_test_hist, learn_rate_hist], \n",
    "                 \"%s_hist.pkl\" % root_name)\n",
    "        print \"optimization history saved\"\n",
    "        log.close()\n",
    "        sess.close()\n",
    "        print \"session and log file closed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLi is used as validation molecule\n",
      "train/test/validation size: 4598/511/1851\n",
      "root name: deep_test\n",
      "batch size: 4598\n",
      "number of batches: 1\n",
      "training set: ['HH', 'HHe+', 'HLi', 'HBe+']\n",
      "validation: HLi\n",
      "learning rate min: 5e-05\n",
      "learning rate steps: 50\n",
      "learning rate start: 1.0\n",
      "learning rate base: 0.8\n",
      "print step: 1\n",
      "threshold: 1e-05\n",
      "maxiter: 100000\n",
      "execuate time: 2017/09/28 15:50:48\n",
      "\n",
      "\n",
      "start from scratch...\n",
      "\n",
      "epoch:     1 train/test/validatoin error: 26.870086/30.120263/32.097009 at rate 1.000000\n",
      "epoch:     2 train/test/validatoin error: 2.008417/1.939163/0.688719 at rate 0.995547\n",
      "epoch:     3 train/test/validatoin error: 1.784662/1.653239/1.242038 at rate 0.991114\n",
      "epoch:     4 train/test/validatoin error: 1.133613/1.233403/0.940112 at rate 0.986701\n",
      "epoch:     5 train/test/validatoin error: 1.265072/1.384170/0.989672 at rate 0.982307\n",
      "epoch:     6 train/test/validatoin error: 1.409429/1.532095/0.994119 at rate 0.977933\n",
      "epoch:     7 train/test/validatoin error: 1.435323/1.554617/0.991420 at rate 0.973578\n",
      "epoch:     8 train/test/validatoin error: 1.440515/1.556295/0.988572 at rate 0.969243\n",
      "epoch:     9 train/test/validatoin error: 1.437899/1.552626/0.984061 at rate 0.964927\n",
      "epoch:    10 train/test/validatoin error: 1.431325/1.546371/0.978772 at rate 0.960630\n",
      "epoch:    11 train/test/validatoin error: 1.422222/1.538222/0.973593 at rate 0.956352\n",
      "epoch:    12 train/test/validatoin error: 1.409152/1.525735/0.970110 at rate 0.952094\n",
      "epoch:    13 train/test/validatoin error: 1.380633/1.496623/0.966091 at rate 0.947854\n",
      "epoch:    14 train/test/validatoin error: 1.329925/1.444014/0.961405 at rate 0.943634\n",
      "epoch:    15 train/test/validatoin error: 1.271292/1.382907/0.956119 at rate 0.939432\n",
      "epoch:    16 train/test/validatoin error: 1.223839/1.332999/0.950445 at rate 0.935248\n",
      "epoch:    17 train/test/validatoin error: 1.191090/1.297914/0.944606 at rate 0.931084\n",
      "epoch:    18 train/test/validatoin error: 1.169270/1.273863/0.938748 at rate 0.926938\n",
      "epoch:    19 train/test/validatoin error: 1.154634/1.257098/0.932947 at rate 0.922810\n",
      "epoch:    20 train/test/validatoin error: 1.144542/1.244976/0.927247 at rate 0.918701\n",
      "epoch:    21 train/test/validatoin error: 1.137275/1.235776/0.921673 at rate 0.914610\n",
      "epoch:    22 train/test/validatoin error: 1.131792/1.228453/0.916232 at rate 0.910537\n",
      "epoch:    23 train/test/validatoin error: 1.127446/1.222353/0.910924 at rate 0.906483\n",
      "epoch:    24 train/test/validatoin error: 1.123827/1.217060/0.905746 at rate 0.902446\n",
      "epoch:    25 train/test/validatoin error: 1.120673/1.212305/0.900690 at rate 0.898428\n",
      "epoch:    26 train/test/validatoin error: 1.117814/1.207909/0.895748 at rate 0.894427\n",
      "epoch:    27 train/test/validatoin error: 1.115138/1.203756/0.890914 at rate 0.890444\n",
      "epoch:    28 train/test/validatoin error: 1.112571/1.199765/0.886179 at rate 0.886479\n",
      "epoch:    29 train/test/validatoin error: 1.110064/1.195881/0.881536 at rate 0.882532\n",
      "epoch:    30 train/test/validatoin error: 1.107585/1.192068/0.876977 at rate 0.878602\n",
      "epoch:    31 train/test/validatoin error: 1.105113/1.188301/0.872496 at rate 0.874690\n",
      "epoch:    32 train/test/validatoin error: 1.102634/1.184560/0.868087 at rate 0.870795\n",
      "epoch:    33 train/test/validatoin error: 1.100142/1.180836/0.863744 at rate 0.866917\n",
      "epoch:    34 train/test/validatoin error: 1.097631/1.177121/0.859462 at rate 0.863057\n",
      "epoch:    35 train/test/validatoin error: 1.095100/1.173410/0.855238 at rate 0.859214\n",
      "epoch:    36 train/test/validatoin error: 1.092548/1.169699/0.851066 at rate 0.855388\n",
      "epoch:    37 train/test/validatoin error: 1.089978/1.165990/0.846944 at rate 0.851579\n",
      "epoch:    38 train/test/validatoin error: 1.087392/1.162280/0.842869 at rate 0.847787\n",
      "epoch:    39 train/test/validatoin error: 1.084791/1.158571/0.838837 at rate 0.844012\n",
      "epoch:    40 train/test/validatoin error: 1.082180/1.154865/0.834847 at rate 0.840253\n",
      "epoch:    41 train/test/validatoin error: 1.079561/1.151163/0.830897 at rate 0.836512\n",
      "epoch:    42 train/test/validatoin error: 1.076776/1.147284/0.826878 at rate 0.832787\n",
      "epoch:    43 train/test/validatoin error: 1.073476/1.142836/0.822572 at rate 0.829078\n",
      "epoch:    44 train/test/validatoin error: 1.069907/1.138093/0.818152 at rate 0.825387\n",
      "epoch:    45 train/test/validatoin error: 1.066150/1.133147/0.813691 at rate 0.821711\n",
      "epoch:    46 train/test/validatoin error: 1.062291/1.128095/0.809261 at rate 0.818052\n",
      "epoch:    47 train/test/validatoin error: 1.058416/1.123029/0.804931 at rate 0.814409\n",
      "epoch:    48 train/test/validatoin error: 1.054598/1.118031/0.800758 at rate 0.810783\n",
      "epoch:    49 train/test/validatoin error: 1.050904/1.113172/0.796789 at rate 0.807173\n",
      "epoch:    50 train/test/validatoin error: 1.047381/1.108505/0.793055 at rate 0.803578\n",
      "epoch:    51 train/test/validatoin error: 1.044062/1.104067/0.789570 at rate 0.800000\n",
      "epoch:    52 train/test/validatoin error: 1.040964/1.099874/0.786330 at rate 0.796438\n",
      "epoch:    53 train/test/validatoin error: 1.038088/1.095929/0.783317 at rate 0.792891\n",
      "epoch:    54 train/test/validatoin error: 1.035422/1.092217/0.780500 at rate 0.789361\n",
      "epoch:    55 train/test/validatoin error: 1.032946/1.088714/0.777842 at rate 0.785846\n",
      "epoch:    56 train/test/validatoin error: 1.030631/1.085389/0.775296 at rate 0.782346\n",
      "epoch:    57 train/test/validatoin error: 1.028445/1.082206/0.772818 at rate 0.778862\n",
      "epoch:    58 train/test/validatoin error: 1.026357/1.079129/0.770364 at rate 0.775394\n",
      "epoch:    59 train/test/validatoin error: 1.024336/1.076125/0.767893 at rate 0.771942\n",
      "epoch:    60 train/test/validatoin error: 1.022358/1.073164/0.765374 at rate 0.768504\n",
      "epoch:    61 train/test/validatoin error: 1.020400/1.070223/0.762780 at rate 0.765082\n",
      "epoch:    62 train/test/validatoin error: 1.018449/1.067287/0.760095 at rate 0.761675\n",
      "epoch:    63 train/test/validatoin error: 1.016497/1.064345/0.757310 at rate 0.758283\n",
      "epoch:    64 train/test/validatoin error: 1.014540/1.061394/0.754423 at rate 0.754907\n",
      "epoch:    65 train/test/validatoin error: 1.012580/1.058436/0.751442 at rate 0.751545\n",
      "epoch:    66 train/test/validatoin error: 1.010625/1.055477/0.748378 at rate 0.748199\n",
      "epoch:    67 train/test/validatoin error: 1.008682/1.052529/0.745247 at rate 0.744867\n",
      "epoch:    68 train/test/validatoin error: 1.006763/1.049602/0.742068 at rate 0.741550\n",
      "epoch:    69 train/test/validatoin error: 1.004879/1.046710/0.738863 at rate 0.738248\n",
      "epoch:    70 train/test/validatoin error: 1.003042/1.043866/0.735653 at rate 0.734961\n",
      "epoch:    71 train/test/validatoin error: 1.001262/1.041081/0.732458 at rate 0.731688\n",
      "epoch:    72 train/test/validatoin error: 0.999547/1.038366/0.729299 at rate 0.728430\n",
      "epoch:    73 train/test/validatoin error: 0.997905/1.035728/0.726192 at rate 0.725186\n",
      "epoch:    74 train/test/validatoin error: 0.996339/1.033173/0.723154 at rate 0.721957\n",
      "epoch:    75 train/test/validatoin error: 0.994850/1.030704/0.720196 at rate 0.718742\n",
      "epoch:    76 train/test/validatoin error: 0.993441/1.028321/0.717329 at rate 0.715542\n",
      "epoch:    77 train/test/validatoin error: 0.992107/1.026024/0.714560 at rate 0.712355\n",
      "epoch:    78 train/test/validatoin error: 0.990846/1.023811/0.711894 at rate 0.709183\n",
      "epoch:    79 train/test/validatoin error: 0.989655/1.021678/0.709334 at rate 0.706025\n",
      "epoch:    80 train/test/validatoin error: 0.988527/1.019621/0.706883 at rate 0.702882\n",
      "epoch:    81 train/test/validatoin error: 0.987460/1.017637/0.704541 at rate 0.699752\n",
      "epoch:    82 train/test/validatoin error: 0.986449/1.015723/0.702309 at rate 0.696636\n",
      "epoch:    83 train/test/validatoin error: 0.985489/1.013875/0.700185 at rate 0.693534\n",
      "epoch:    84 train/test/validatoin error: 0.984579/1.012092/0.698169 at rate 0.690445\n",
      "epoch:    85 train/test/validatoin error: 0.983716/1.010372/0.696260 at rate 0.687371\n",
      "epoch:    86 train/test/validatoin error: 0.982897/1.008715/0.694455 at rate 0.684310\n",
      "epoch:    87 train/test/validatoin error: 0.982123/1.007121/0.692753 at rate 0.681263\n",
      "epoch:    88 train/test/validatoin error: 0.981393/1.005590/0.691153 at rate 0.678229\n",
      "epoch:    89 train/test/validatoin error: 0.980707/1.004124/0.689651 at rate 0.675209\n",
      "epoch:    90 train/test/validatoin error: 0.980064/1.002723/0.688244 at rate 0.672203\n",
      "epoch:    91 train/test/validatoin error: 0.979464/1.001388/0.686930 at rate 0.669209\n",
      "epoch:    92 train/test/validatoin error: 0.978907/1.000119/0.685703 at rate 0.666229\n",
      "epoch:    93 train/test/validatoin error: 0.978393/0.998916/0.684560 at rate 0.663263\n",
      "epoch:    94 train/test/validatoin error: 0.977919/0.997778/0.683496 at rate 0.660309\n",
      "epoch:    95 train/test/validatoin error: 0.977485/0.996705/0.682506 at rate 0.657369\n",
      "epoch:    96 train/test/validatoin error: 0.977089/0.995694/0.681584 at rate 0.654442\n",
      "epoch:    97 train/test/validatoin error: 0.976728/0.994745/0.680724 at rate 0.651528\n",
      "epoch:    98 train/test/validatoin error: 0.976400/0.993854/0.679923 at rate 0.648626\n",
      "epoch:    99 train/test/validatoin error: 0.976103/0.993019/0.679174 at rate 0.645738\n",
      "epoch:   100 train/test/validatoin error: 0.975833/0.992238/0.678473 at rate 0.642863\n",
      "epoch:   101 train/test/validatoin error: 0.975588/0.991507/0.677816 at rate 0.640000\n",
      "epoch:   102 train/test/validatoin error: 0.975366/0.990825/0.677199 at rate 0.637150\n",
      "epoch:   103 train/test/validatoin error: 0.975164/0.990189/0.676620 at rate 0.634313\n",
      "epoch:   104 train/test/validatoin error: 0.974980/0.989596/0.676075 at rate 0.631488\n",
      "epoch:   105 train/test/validatoin error: 0.974811/0.989043/0.675563 at rate 0.628676\n",
      "epoch:   106 train/test/validatoin error: 0.974657/0.988529/0.675082 at rate 0.625877\n",
      "epoch:   107 train/test/validatoin error: 0.974515/0.988052/0.674631 at rate 0.623090\n",
      "epoch:   108 train/test/validatoin error: 0.974384/0.987610/0.674210 at rate 0.620315\n",
      "epoch:   109 train/test/validatoin error: 0.974263/0.987201/0.673818 at rate 0.617553\n",
      "epoch:   110 train/test/validatoin error: 0.974151/0.986824/0.673456 at rate 0.614803\n",
      "epoch:   111 train/test/validatoin error: 0.974047/0.986477/0.673123 at rate 0.612066\n",
      "epoch:   112 train/test/validatoin error: 0.973950/0.986158/0.672820 at rate 0.609340\n",
      "epoch:   113 train/test/validatoin error: 0.973859/0.985867/0.672546 at rate 0.606627\n",
      "epoch:   114 train/test/validatoin error: 0.973773/0.985602/0.672302 at rate 0.603926\n",
      "epoch:   115 train/test/validatoin error: 0.973693/0.985361/0.672088 at rate 0.601236\n",
      "epoch:   116 train/test/validatoin error: 0.973617/0.985143/0.671903 at rate 0.598559\n",
      "epoch:   117 train/test/validatoin error: 0.973545/0.984946/0.671748 at rate 0.595894\n",
      "epoch:   118 train/test/validatoin error: 0.973476/0.984770/0.671621 at rate 0.593240\n",
      "epoch:   119 train/test/validatoin error: 0.973411/0.984613/0.671522 at rate 0.590599\n",
      "epoch:   120 train/test/validatoin error: 0.973348/0.984474/0.671449 at rate 0.587969\n",
      "epoch:   121 train/test/validatoin error: 0.973288/0.984350/0.671403 at rate 0.585350\n",
      "epoch:   122 train/test/validatoin error: 0.973230/0.984242/0.671381 at rate 0.582744\n",
      "epoch:   123 train/test/validatoin error: 0.973174/0.984148/0.671382 at rate 0.580149\n",
      "epoch:   124 train/test/validatoin error: 0.973121/0.984067/0.671405 at rate 0.577566\n",
      "epoch:   125 train/test/validatoin error: 0.973068/0.983998/0.671447 at rate 0.574994\n",
      "epoch:   126 train/test/validatoin error: 0.973018/0.983939/0.671509 at rate 0.572433\n",
      "epoch:   127 train/test/validatoin error: 0.972969/0.983890/0.671587 at rate 0.569884\n",
      "epoch:   128 train/test/validatoin error: 0.972922/0.983850/0.671679 at rate 0.567347\n",
      "epoch:   129 train/test/validatoin error: 0.972876/0.983818/0.671785 at rate 0.564820\n",
      "epoch:   130 train/test/validatoin error: 0.972832/0.983793/0.671902 at rate 0.562305\n",
      "epoch:   131 train/test/validatoin error: 0.972789/0.983775/0.672029 at rate 0.559801\n",
      "epoch:   132 train/test/validatoin error: 0.972748/0.983763/0.672164 at rate 0.557309\n",
      "epoch:   133 train/test/validatoin error: 0.972709/0.983755/0.672306 at rate 0.554827\n",
      "epoch:   134 train/test/validatoin error: 0.972671/0.983752/0.672452 at rate 0.552356\n",
      "epoch:   135 train/test/validatoin error: 0.972635/0.983753/0.672602 at rate 0.549897\n",
      "epoch:   136 train/test/validatoin error: 0.972600/0.983757/0.672754 at rate 0.547448\n",
      "epoch:   137 train/test/validatoin error: 0.972566/0.983763/0.672907 at rate 0.545010\n",
      "epoch:   138 train/test/validatoin error: 0.972534/0.983772/0.673060 at rate 0.542583\n",
      "epoch:   139 train/test/validatoin error: 0.972504/0.983782/0.673213 at rate 0.540167\n",
      "epoch:   140 train/test/validatoin error: 0.972475/0.983794/0.673363 at rate 0.537762\n",
      "epoch:   141 train/test/validatoin error: 0.972446/0.983807/0.673511 at rate 0.535367\n",
      "epoch:   142 train/test/validatoin error: 0.972420/0.983820/0.673656 at rate 0.532984\n",
      "epoch:   143 train/test/validatoin error: 0.972394/0.983834/0.673797 at rate 0.530610\n",
      "epoch:   144 train/test/validatoin error: 0.972369/0.983848/0.673935 at rate 0.528247\n",
      "epoch:   145 train/test/validatoin error: 0.972346/0.983861/0.674069 at rate 0.525895\n",
      "epoch:   146 train/test/validatoin error: 0.972323/0.983874/0.674198 at rate 0.523553\n",
      "epoch:   147 train/test/validatoin error: 0.972302/0.983887/0.674323 at rate 0.521222\n",
      "epoch:   148 train/test/validatoin error: 0.972281/0.983899/0.674443 at rate 0.518901\n",
      "epoch:   149 train/test/validatoin error: 0.972261/0.983910/0.674559 at rate 0.516590\n",
      "epoch:   150 train/test/validatoin error: 0.972242/0.983919/0.674671 at rate 0.514290\n",
      "epoch:   151 train/test/validatoin error: 0.972223/0.983928/0.674779 at rate 0.512000\n",
      "epoch:   152 train/test/validatoin error: 0.972206/0.983936/0.674883 at rate 0.509720\n",
      "epoch:   153 train/test/validatoin error: 0.972189/0.983943/0.674983 at rate 0.507450\n",
      "epoch:   154 train/test/validatoin error: 0.972173/0.983948/0.675079 at rate 0.505191\n",
      "epoch:   155 train/test/validatoin error: 0.972157/0.983953/0.675172 at rate 0.502941\n",
      "epoch:   156 train/test/validatoin error: 0.972142/0.983956/0.675262 at rate 0.500702\n",
      "epoch:   157 train/test/validatoin error: 0.972127/0.983958/0.675350 at rate 0.498472\n",
      "epoch:   158 train/test/validatoin error: 0.972113/0.983959/0.675434 at rate 0.496252\n",
      "epoch:   159 train/test/validatoin error: 0.972099/0.983959/0.675516 at rate 0.494043\n",
      "epoch:   160 train/test/validatoin error: 0.972086/0.983958/0.675595 at rate 0.491843\n",
      "epoch:   161 train/test/validatoin error: 0.972074/0.983956/0.675673 at rate 0.489652\n",
      "epoch:   162 train/test/validatoin error: 0.972061/0.983953/0.675748 at rate 0.487472\n",
      "epoch:   163 train/test/validatoin error: 0.972049/0.983949/0.675821 at rate 0.485301\n",
      "epoch:   164 train/test/validatoin error: 0.972038/0.983944/0.675893 at rate 0.483140\n",
      "epoch:   165 train/test/validatoin error: 0.972027/0.983938/0.675963 at rate 0.480989\n",
      "epoch:   166 train/test/validatoin error: 0.972016/0.983932/0.676032 at rate 0.478847\n",
      "epoch:   167 train/test/validatoin error: 0.972005/0.983925/0.676099 at rate 0.476715\n",
      "epoch:   168 train/test/validatoin error: 0.971995/0.983918/0.676164 at rate 0.474592\n",
      "epoch:   169 train/test/validatoin error: 0.971985/0.983909/0.676229 at rate 0.472479\n",
      "epoch:   170 train/test/validatoin error: 0.971975/0.983901/0.676292 at rate 0.470375\n",
      "epoch:   171 train/test/validatoin error: 0.971966/0.983892/0.676354 at rate 0.468280\n",
      "epoch:   172 train/test/validatoin error: 0.971957/0.983882/0.676415 at rate 0.466195\n",
      "epoch:   173 train/test/validatoin error: 0.971948/0.983872/0.676474 at rate 0.464119\n",
      "epoch:   174 train/test/validatoin error: 0.971939/0.983862/0.676533 at rate 0.462053\n",
      "epoch:   175 train/test/validatoin error: 0.971931/0.983852/0.676590 at rate 0.459995\n",
      "epoch:   176 train/test/validatoin error: 0.971923/0.983842/0.676647 at rate 0.457947\n",
      "epoch:   177 train/test/validatoin error: 0.971915/0.983831/0.676702 at rate 0.455908\n",
      "epoch:   178 train/test/validatoin error: 0.971907/0.983820/0.676756 at rate 0.453877\n",
      "epoch:   179 train/test/validatoin error: 0.971899/0.983810/0.676809 at rate 0.451856\n",
      "epoch:   180 train/test/validatoin error: 0.971892/0.983799/0.676862 at rate 0.449844\n",
      "epoch:   181 train/test/validatoin error: 0.971885/0.983789/0.676913 at rate 0.447841\n",
      "epoch:   182 train/test/validatoin error: 0.971878/0.983778/0.676964 at rate 0.445847\n",
      "epoch:   183 train/test/validatoin error: 0.971871/0.983768/0.677013 at rate 0.443862\n",
      "epoch:   184 train/test/validatoin error: 0.971864/0.983757/0.677062 at rate 0.441885\n",
      "epoch:   185 train/test/validatoin error: 0.971858/0.983747/0.677110 at rate 0.439917\n",
      "epoch:   186 train/test/validatoin error: 0.971851/0.983737/0.677158 at rate 0.437959\n",
      "epoch:   187 train/test/validatoin error: 0.971845/0.983728/0.677204 at rate 0.436008\n",
      "epoch:   188 train/test/validatoin error: 0.971839/0.983718/0.677250 at rate 0.434067\n",
      "epoch:   189 train/test/validatoin error: 0.971833/0.983709/0.677296 at rate 0.432134\n",
      "epoch:   190 train/test/validatoin error: 0.971827/0.983700/0.677341 at rate 0.430210\n",
      "epoch:   191 train/test/validatoin error: 0.971822/0.983692/0.677385 at rate 0.428294\n",
      "epoch:   192 train/test/validatoin error: 0.971816/0.983683/0.677429 at rate 0.426387\n",
      "epoch:   193 train/test/validatoin error: 0.971811/0.983675/0.677472 at rate 0.424488\n",
      "epoch:   194 train/test/validatoin error: 0.971806/0.983667/0.677515 at rate 0.422598\n",
      "epoch:   195 train/test/validatoin error: 0.971800/0.983660/0.677558 at rate 0.420716\n",
      "epoch:   196 train/test/validatoin error: 0.971795/0.983653/0.677600 at rate 0.418843\n",
      "epoch:   197 train/test/validatoin error: 0.971790/0.983646/0.677642 at rate 0.416978\n",
      "epoch:   198 train/test/validatoin error: 0.971785/0.983639/0.677684 at rate 0.415121\n",
      "epoch:   199 train/test/validatoin error: 0.971781/0.983633/0.677725 at rate 0.413272\n",
      "epoch:   200 train/test/validatoin error: 0.971776/0.983627/0.677767 at rate 0.411432\n",
      "epoch:   201 train/test/validatoin error: 0.971772/0.983622/0.677808 at rate 0.409600\n",
      "epoch:   202 train/test/validatoin error: 0.971767/0.983616/0.677848 at rate 0.407776\n",
      "epoch:   203 train/test/validatoin error: 0.971763/0.983611/0.677889 at rate 0.405960\n",
      "epoch:   204 train/test/validatoin error: 0.971758/0.983607/0.677930 at rate 0.404153\n",
      "epoch:   205 train/test/validatoin error: 0.971754/0.983602/0.677970 at rate 0.402353\n",
      "epoch:   206 train/test/validatoin error: 0.971750/0.983598/0.678010 at rate 0.400561\n",
      "epoch:   207 train/test/validatoin error: 0.971746/0.983594/0.678050 at rate 0.398778\n",
      "epoch:   208 train/test/validatoin error: 0.971742/0.983590/0.678090 at rate 0.397002\n",
      "epoch:   209 train/test/validatoin error: 0.971738/0.983587/0.678130 at rate 0.395234\n",
      "epoch:   210 train/test/validatoin error: 0.971735/0.983584/0.678169 at rate 0.393474\n",
      "epoch:   211 train/test/validatoin error: 0.971731/0.983581/0.678209 at rate 0.391722\n",
      "epoch:   212 train/test/validatoin error: 0.971727/0.983578/0.678248 at rate 0.389978\n",
      "epoch:   213 train/test/validatoin error: 0.971724/0.983576/0.678287 at rate 0.388241\n",
      "epoch:   214 train/test/validatoin error: 0.971720/0.983574/0.678326 at rate 0.386512\n",
      "epoch:   215 train/test/validatoin error: 0.971717/0.983572/0.678364 at rate 0.384791\n",
      "epoch:   216 train/test/validatoin error: 0.971713/0.983570/0.678402 at rate 0.383078\n",
      "epoch:   217 train/test/validatoin error: 0.971710/0.983568/0.678440 at rate 0.381372\n",
      "epoch:   218 train/test/validatoin error: 0.971706/0.983567/0.678478 at rate 0.379674\n",
      "epoch:   219 train/test/validatoin error: 0.971703/0.983565/0.678516 at rate 0.377983\n",
      "epoch:   220 train/test/validatoin error: 0.971700/0.983564/0.678553 at rate 0.376300\n",
      "epoch:   221 train/test/validatoin error: 0.971697/0.983563/0.678590 at rate 0.374624\n",
      "epoch:   222 train/test/validatoin error: 0.971694/0.983562/0.678627 at rate 0.372956\n",
      "epoch:   223 train/test/validatoin error: 0.971691/0.983562/0.678663 at rate 0.371295\n",
      "epoch:   224 train/test/validatoin error: 0.971688/0.983561/0.678700 at rate 0.369642\n",
      "epoch:   225 train/test/validatoin error: 0.971685/0.983561/0.678736 at rate 0.367996\n",
      "epoch:   226 train/test/validatoin error: 0.971682/0.983560/0.678771 at rate 0.366357\n",
      "epoch:   227 train/test/validatoin error: 0.971679/0.983560/0.678806 at rate 0.364726\n",
      "epoch:   228 train/test/validatoin error: 0.971676/0.983560/0.678841 at rate 0.363102\n",
      "epoch:   229 train/test/validatoin error: 0.971674/0.983560/0.678876 at rate 0.361485\n",
      "epoch:   230 train/test/validatoin error: 0.971671/0.983560/0.678910 at rate 0.359875\n",
      "epoch:   231 train/test/validatoin error: 0.971668/0.983560/0.678944 at rate 0.358273\n",
      "epoch:   232 train/test/validatoin error: 0.971666/0.983560/0.678978 at rate 0.356678\n",
      "epoch:   233 train/test/validatoin error: 0.971663/0.983560/0.679011 at rate 0.355089\n",
      "epoch:   234 train/test/validatoin error: 0.971661/0.983561/0.679044 at rate 0.353508\n",
      "epoch:   235 train/test/validatoin error: 0.971658/0.983561/0.679077 at rate 0.351934\n",
      "epoch:   236 train/test/validatoin error: 0.971656/0.983562/0.679109 at rate 0.350367\n",
      "epoch:   237 train/test/validatoin error: 0.971653/0.983562/0.679141 at rate 0.348807\n",
      "epoch:   238 train/test/validatoin error: 0.971651/0.983563/0.679172 at rate 0.347253\n",
      "epoch:   239 train/test/validatoin error: 0.971648/0.983563/0.679204 at rate 0.345707\n",
      "epoch:   240 train/test/validatoin error: 0.971646/0.983564/0.679235 at rate 0.344168\n",
      "epoch:   241 train/test/validatoin error: 0.971644/0.983565/0.679266 at rate 0.342635\n",
      "epoch:   242 train/test/validatoin error: 0.971642/0.983566/0.679296 at rate 0.341109\n",
      "epoch:   243 train/test/validatoin error: 0.971639/0.983567/0.679326 at rate 0.339591\n",
      "epoch:   244 train/test/validatoin error: 0.971637/0.983567/0.679356 at rate 0.338078\n",
      "epoch:   245 train/test/validatoin error: 0.971635/0.983568/0.679385 at rate 0.336573\n",
      "epoch:   246 train/test/validatoin error: 0.971633/0.983569/0.679415 at rate 0.335074\n",
      "epoch:   247 train/test/validatoin error: 0.971631/0.983570/0.679444 at rate 0.333582\n",
      "epoch:   248 train/test/validatoin error: 0.971629/0.983571/0.679472 at rate 0.332097\n",
      "epoch:   249 train/test/validatoin error: 0.971627/0.983572/0.679500 at rate 0.330618\n",
      "epoch:   250 train/test/validatoin error: 0.971624/0.983573/0.679529 at rate 0.329146\n",
      "epoch:   251 train/test/validatoin error: 0.971622/0.983575/0.679556 at rate 0.327680\n",
      "epoch:   252 train/test/validatoin error: 0.971620/0.983576/0.679584 at rate 0.326221\n",
      "epoch:   253 train/test/validatoin error: 0.971618/0.983577/0.679611 at rate 0.324768\n",
      "epoch:   254 train/test/validatoin error: 0.971617/0.983578/0.679638 at rate 0.323322\n",
      "epoch:   255 train/test/validatoin error: 0.971615/0.983579/0.679665 at rate 0.321882\n",
      "epoch:   256 train/test/validatoin error: 0.971613/0.983580/0.679691 at rate 0.320449\n",
      "epoch:   257 train/test/validatoin error: 0.971611/0.983582/0.679717 at rate 0.319022\n",
      "epoch:   258 train/test/validatoin error: 0.971609/0.983583/0.679743 at rate 0.317602\n",
      "epoch:   259 train/test/validatoin error: 0.971607/0.983584/0.679769 at rate 0.316187\n",
      "epoch:   260 train/test/validatoin error: 0.971605/0.983586/0.679794 at rate 0.314779\n",
      "epoch:   261 train/test/validatoin error: 0.971604/0.983587/0.679819 at rate 0.313378\n",
      "epoch:   262 train/test/validatoin error: 0.971602/0.983588/0.679844 at rate 0.311982\n",
      "epoch:   263 train/test/validatoin error: 0.971600/0.983590/0.679869 at rate 0.310593\n",
      "epoch:   264 train/test/validatoin error: 0.971598/0.983591/0.679893 at rate 0.309210\n",
      "epoch:   265 train/test/validatoin error: 0.971597/0.983592/0.679917 at rate 0.307833\n",
      "epoch:   266 train/test/validatoin error: 0.971595/0.983594/0.679941 at rate 0.306462\n",
      "epoch:   267 train/test/validatoin error: 0.971593/0.983595/0.679965 at rate 0.305098\n",
      "epoch:   268 train/test/validatoin error: 0.971592/0.983597/0.679988 at rate 0.303739\n",
      "epoch:   269 train/test/validatoin error: 0.971590/0.983598/0.680011 at rate 0.302386\n",
      "epoch:   270 train/test/validatoin error: 0.971588/0.983600/0.680034 at rate 0.301040\n",
      "epoch:   271 train/test/validatoin error: 0.971587/0.983601/0.680057 at rate 0.299699\n",
      "epoch:   272 train/test/validatoin error: 0.971585/0.983603/0.680080 at rate 0.298365\n",
      "epoch:   273 train/test/validatoin error: 0.971584/0.983604/0.680102 at rate 0.297036\n",
      "epoch:   274 train/test/validatoin error: 0.971582/0.983606/0.680124 at rate 0.295714\n",
      "epoch:   275 train/test/validatoin error: 0.971580/0.983607/0.680146 at rate 0.294397\n",
      "epoch:   276 train/test/validatoin error: 0.971579/0.983609/0.680168 at rate 0.293086\n",
      "epoch:   277 train/test/validatoin error: 0.971577/0.983610/0.680189 at rate 0.291781\n",
      "epoch:   278 train/test/validatoin error: 0.971576/0.983612/0.680210 at rate 0.290482\n",
      "epoch:   279 train/test/validatoin error: 0.971574/0.983613/0.680232 at rate 0.289188\n",
      "epoch:   280 train/test/validatoin error: 0.971573/0.983615/0.680252 at rate 0.287900\n",
      "epoch:   281 train/test/validatoin error: 0.971571/0.983617/0.680273 at rate 0.286618\n",
      "epoch:   282 train/test/validatoin error: 0.971570/0.983618/0.680294 at rate 0.285342\n",
      "epoch:   283 train/test/validatoin error: 0.971569/0.983620/0.680314 at rate 0.284071\n",
      "epoch:   284 train/test/validatoin error: 0.971567/0.983622/0.680334 at rate 0.282806\n",
      "epoch:   285 train/test/validatoin error: 0.971566/0.983623/0.680354 at rate 0.281547\n",
      "epoch:   286 train/test/validatoin error: 0.971564/0.983625/0.680374 at rate 0.280293\n",
      "epoch:   287 train/test/validatoin error: 0.971563/0.983627/0.680393 at rate 0.279045\n",
      "epoch:   288 train/test/validatoin error: 0.971562/0.983628/0.680412 at rate 0.277803\n",
      "epoch:   289 train/test/validatoin error: 0.971560/0.983630/0.680432 at rate 0.276566\n",
      "epoch:   290 train/test/validatoin error: 0.971559/0.983632/0.680451 at rate 0.275334\n",
      "epoch:   291 train/test/validatoin error: 0.971557/0.983633/0.680469 at rate 0.274108\n",
      "epoch:   292 train/test/validatoin error: 0.971556/0.983635/0.680488 at rate 0.272888\n",
      "epoch:   293 train/test/validatoin error: 0.971555/0.983637/0.680507 at rate 0.271672\n",
      "epoch:   294 train/test/validatoin error: 0.971554/0.983639/0.680525 at rate 0.270463\n",
      "epoch:   295 train/test/validatoin error: 0.971552/0.983640/0.680543 at rate 0.269258\n",
      "epoch:   296 train/test/validatoin error: 0.971551/0.983642/0.680561 at rate 0.268059\n",
      "epoch:   297 train/test/validatoin error: 0.971550/0.983644/0.680579 at rate 0.266866\n",
      "epoch:   298 train/test/validatoin error: 0.971548/0.983646/0.680597 at rate 0.265677\n",
      "epoch:   299 train/test/validatoin error: 0.971547/0.983647/0.680614 at rate 0.264494\n",
      "epoch:   300 train/test/validatoin error: 0.971546/0.983649/0.680632 at rate 0.263317\n",
      "epoch:   301 train/test/validatoin error: 0.971545/0.983651/0.680649 at rate 0.262144\n",
      "epoch:   302 train/test/validatoin error: 0.971543/0.983653/0.680666 at rate 0.260977\n",
      "epoch:   303 train/test/validatoin error: 0.971542/0.983655/0.680683 at rate 0.259815\n",
      "epoch:   304 train/test/validatoin error: 0.971541/0.983656/0.680700 at rate 0.258658\n",
      "epoch:   305 train/test/validatoin error: 0.971540/0.983658/0.680716 at rate 0.257506\n",
      "epoch:   306 train/test/validatoin error: 0.971539/0.983660/0.680733 at rate 0.256359\n",
      "epoch:   307 train/test/validatoin error: 0.971537/0.983662/0.680749 at rate 0.255218\n",
      "epoch:   308 train/test/validatoin error: 0.971536/0.983664/0.680765 at rate 0.254081\n",
      "epoch:   309 train/test/validatoin error: 0.971535/0.983665/0.680781 at rate 0.252950\n",
      "epoch:   310 train/test/validatoin error: 0.971534/0.983667/0.680797 at rate 0.251823\n",
      "epoch:   311 train/test/validatoin error: 0.971533/0.983669/0.680813 at rate 0.250702\n",
      "epoch:   312 train/test/validatoin error: 0.971532/0.983671/0.680829 at rate 0.249586\n",
      "epoch:   313 train/test/validatoin error: 0.971531/0.983673/0.680844 at rate 0.248474\n",
      "epoch:   314 train/test/validatoin error: 0.971529/0.983675/0.680860 at rate 0.247368\n",
      "epoch:   315 train/test/validatoin error: 0.971528/0.983676/0.680875 at rate 0.246266\n",
      "epoch:   316 train/test/validatoin error: 0.971527/0.983678/0.680890 at rate 0.245170\n",
      "epoch:   317 train/test/validatoin error: 0.971526/0.983680/0.680905 at rate 0.244078\n",
      "epoch:   318 train/test/validatoin error: 0.971525/0.983682/0.680920 at rate 0.242991\n",
      "epoch:   319 train/test/validatoin error: 0.971524/0.983684/0.680935 at rate 0.241909\n",
      "epoch:   320 train/test/validatoin error: 0.971523/0.983686/0.680949 at rate 0.240832\n",
      "epoch:   321 train/test/validatoin error: 0.971522/0.983688/0.680964 at rate 0.239760\n",
      "epoch:   322 train/test/validatoin error: 0.971521/0.983689/0.680978 at rate 0.238692\n",
      "epoch:   323 train/test/validatoin error: 0.971520/0.983691/0.680993 at rate 0.237629\n",
      "epoch:   324 train/test/validatoin error: 0.971519/0.983693/0.681007 at rate 0.236571\n",
      "epoch:   325 train/test/validatoin error: 0.971518/0.983695/0.681021 at rate 0.235517\n",
      "epoch:   326 train/test/validatoin error: 0.971517/0.983697/0.681035 at rate 0.234469\n",
      "epoch:   327 train/test/validatoin error: 0.971515/0.983699/0.681049 at rate 0.233425\n",
      "epoch:   328 train/test/validatoin error: 0.971514/0.983701/0.681063 at rate 0.232385\n",
      "epoch:   329 train/test/validatoin error: 0.971513/0.983703/0.681076 at rate 0.231350\n",
      "epoch:   330 train/test/validatoin error: 0.971512/0.983704/0.681090 at rate 0.230320\n",
      "epoch:   331 train/test/validatoin error: 0.971511/0.983706/0.681103 at rate 0.229295\n",
      "epoch:   332 train/test/validatoin error: 0.971510/0.983708/0.681116 at rate 0.228274\n",
      "epoch:   333 train/test/validatoin error: 0.971509/0.983710/0.681130 at rate 0.227257\n",
      "epoch:   334 train/test/validatoin error: 0.971508/0.983712/0.681143 at rate 0.226245\n",
      "epoch:   335 train/test/validatoin error: 0.971507/0.983714/0.681156 at rate 0.225238\n",
      "epoch:   336 train/test/validatoin error: 0.971506/0.983716/0.681169 at rate 0.224235\n",
      "epoch:   337 train/test/validatoin error: 0.971506/0.983718/0.681181 at rate 0.223236\n",
      "epoch:   338 train/test/validatoin error: 0.971505/0.983719/0.681194 at rate 0.222242\n",
      "epoch:   339 train/test/validatoin error: 0.971504/0.983721/0.681207 at rate 0.221253\n",
      "epoch:   340 train/test/validatoin error: 0.971503/0.983723/0.681219 at rate 0.220267\n",
      "epoch:   341 train/test/validatoin error: 0.971502/0.983725/0.681232 at rate 0.219287\n",
      "epoch:   342 train/test/validatoin error: 0.971501/0.983727/0.681244 at rate 0.218310\n",
      "epoch:   343 train/test/validatoin error: 0.971500/0.983729/0.681256 at rate 0.217338\n",
      "epoch:   344 train/test/validatoin error: 0.971499/0.983731/0.681268 at rate 0.216370\n",
      "epoch:   345 train/test/validatoin error: 0.971498/0.983732/0.681280 at rate 0.215407\n",
      "epoch:   346 train/test/validatoin error: 0.971497/0.983734/0.681292 at rate 0.214447\n",
      "epoch:   347 train/test/validatoin error: 0.971496/0.983736/0.681304 at rate 0.213493\n",
      "epoch:   348 train/test/validatoin error: 0.971495/0.983738/0.681316 at rate 0.212542\n",
      "epoch:   349 train/test/validatoin error: 0.971494/0.983740/0.681327 at rate 0.211595\n",
      "epoch:   350 train/test/validatoin error: 0.971493/0.983742/0.681339 at rate 0.210653\n",
      "epoch:   351 train/test/validatoin error: 0.971493/0.983744/0.681350 at rate 0.209715\n",
      "epoch:   352 train/test/validatoin error: 0.971492/0.983746/0.681362 at rate 0.208781\n",
      "epoch:   353 train/test/validatoin error: 0.971491/0.983747/0.681373 at rate 0.207852\n",
      "epoch:   354 train/test/validatoin error: 0.971490/0.983749/0.681384 at rate 0.206926\n",
      "epoch:   355 train/test/validatoin error: 0.971489/0.983751/0.681396 at rate 0.206005\n",
      "epoch:   356 train/test/validatoin error: 0.971488/0.983753/0.681407 at rate 0.205087\n",
      "epoch:   357 train/test/validatoin error: 0.971487/0.983755/0.681418 at rate 0.204174\n",
      "epoch:   358 train/test/validatoin error: 0.971486/0.983757/0.681429 at rate 0.203265\n",
      "epoch:   359 train/test/validatoin error: 0.971486/0.983758/0.681439 at rate 0.202360\n",
      "epoch:   360 train/test/validatoin error: 0.971485/0.983760/0.681450 at rate 0.201459\n",
      "epoch:   361 train/test/validatoin error: 0.971484/0.983762/0.681461 at rate 0.200562\n",
      "epoch:   362 train/test/validatoin error: 0.971483/0.983764/0.681471 at rate 0.199669\n",
      "epoch:   363 train/test/validatoin error: 0.971482/0.983766/0.681482 at rate 0.198779\n",
      "epoch:   364 train/test/validatoin error: 0.971481/0.983768/0.681492 at rate 0.197894\n",
      "epoch:   365 train/test/validatoin error: 0.971480/0.983769/0.681503 at rate 0.197013\n",
      "epoch:   366 train/test/validatoin error: 0.971480/0.983771/0.681513 at rate 0.196136\n",
      "epoch:   367 train/test/validatoin error: 0.971479/0.983773/0.681523 at rate 0.195262\n",
      "epoch:   368 train/test/validatoin error: 0.971478/0.983775/0.681533 at rate 0.194393\n",
      "epoch:   369 train/test/validatoin error: 0.971477/0.983777/0.681544 at rate 0.193527\n",
      "epoch:   370 train/test/validatoin error: 0.971476/0.983779/0.681554 at rate 0.192666\n",
      "epoch:   371 train/test/validatoin error: 0.971476/0.983780/0.681564 at rate 0.191808\n",
      "epoch:   372 train/test/validatoin error: 0.971475/0.983782/0.681573 at rate 0.190954\n",
      "epoch:   373 train/test/validatoin error: 0.971474/0.983784/0.681583 at rate 0.190103\n",
      "epoch:   374 train/test/validatoin error: 0.971473/0.983786/0.681593 at rate 0.189257\n",
      "epoch:   375 train/test/validatoin error: 0.971472/0.983788/0.681603 at rate 0.188414\n",
      "epoch:   376 train/test/validatoin error: 0.971472/0.983789/0.681612 at rate 0.187575\n",
      "epoch:   377 train/test/validatoin error: 0.971471/0.983791/0.681622 at rate 0.186740\n",
      "epoch:   378 train/test/validatoin error: 0.971470/0.983793/0.681631 at rate 0.185908\n",
      "epoch:   379 train/test/validatoin error: 0.971469/0.983795/0.681641 at rate 0.185080\n",
      "epoch:   380 train/test/validatoin error: 0.971469/0.983797/0.681650 at rate 0.184256\n",
      "epoch:   381 train/test/validatoin error: 0.971468/0.983798/0.681659 at rate 0.183436\n",
      "epoch:   382 train/test/validatoin error: 0.971467/0.983800/0.681669 at rate 0.182619\n",
      "epoch:   383 train/test/validatoin error: 0.971466/0.983802/0.681678 at rate 0.181806\n",
      "epoch:   384 train/test/validatoin error: 0.971466/0.983804/0.681687 at rate 0.180996\n",
      "epoch:   385 train/test/validatoin error: 0.971465/0.983805/0.681696 at rate 0.180190\n",
      "epoch:   386 train/test/validatoin error: 0.971464/0.983807/0.681705 at rate 0.179388\n",
      "epoch:   387 train/test/validatoin error: 0.971463/0.983809/0.681714 at rate 0.178589\n",
      "epoch:   388 train/test/validatoin error: 0.971463/0.983811/0.681723 at rate 0.177794\n",
      "epoch:   389 train/test/validatoin error: 0.971462/0.983812/0.681731 at rate 0.177002\n",
      "epoch:   390 train/test/validatoin error: 0.971461/0.983814/0.681740 at rate 0.176214\n",
      "epoch:   391 train/test/validatoin error: 0.971460/0.983816/0.681749 at rate 0.175429\n",
      "epoch:   392 train/test/validatoin error: 0.971460/0.983818/0.681757 at rate 0.174648\n",
      "epoch:   393 train/test/validatoin error: 0.971459/0.983819/0.681766 at rate 0.173870\n",
      "epoch:   394 train/test/validatoin error: 0.971458/0.983821/0.681775 at rate 0.173096\n",
      "epoch:   395 train/test/validatoin error: 0.971457/0.983823/0.681783 at rate 0.172325\n",
      "epoch:   396 train/test/validatoin error: 0.971457/0.983825/0.681791 at rate 0.171558\n",
      "epoch:   397 train/test/validatoin error: 0.971456/0.983826/0.681800 at rate 0.170794\n",
      "epoch:   398 train/test/validatoin error: 0.971455/0.983828/0.681808 at rate 0.170034\n",
      "epoch:   399 train/test/validatoin error: 0.971455/0.983830/0.681816 at rate 0.169276\n",
      "epoch:   400 train/test/validatoin error: 0.971454/0.983831/0.681824 at rate 0.168523\n",
      "epoch:   401 train/test/validatoin error: 0.971453/0.983833/0.681833 at rate 0.167772\n",
      "epoch:   402 train/test/validatoin error: 0.971453/0.983835/0.681841 at rate 0.167025\n",
      "epoch:   403 train/test/validatoin error: 0.971452/0.983837/0.681849 at rate 0.166281\n",
      "epoch:   404 train/test/validatoin error: 0.971451/0.983838/0.681857 at rate 0.165541\n",
      "epoch:   405 train/test/validatoin error: 0.971450/0.983840/0.681865 at rate 0.164804\n",
      "epoch:   406 train/test/validatoin error: 0.971450/0.983842/0.681873 at rate 0.164070\n",
      "epoch:   407 train/test/validatoin error: 0.971449/0.983843/0.681880 at rate 0.163339\n",
      "epoch:   408 train/test/validatoin error: 0.971448/0.983845/0.681888 at rate 0.162612\n",
      "epoch:   409 train/test/validatoin error: 0.971448/0.983847/0.681896 at rate 0.161888\n",
      "epoch:   410 train/test/validatoin error: 0.971447/0.983848/0.681904 at rate 0.161167\n",
      "epoch:   411 train/test/validatoin error: 0.971446/0.983850/0.681911 at rate 0.160449\n",
      "epoch:   412 train/test/validatoin error: 0.971446/0.983852/0.681919 at rate 0.159735\n",
      "epoch:   413 train/test/validatoin error: 0.971445/0.983853/0.681926 at rate 0.159024\n",
      "epoch:   414 train/test/validatoin error: 0.971444/0.983855/0.681934 at rate 0.158315\n",
      "epoch:   415 train/test/validatoin error: 0.971444/0.983857/0.681941 at rate 0.157611\n",
      "epoch:   416 train/test/validatoin error: 0.971443/0.983858/0.681949 at rate 0.156909\n",
      "epoch:   417 train/test/validatoin error: 0.971443/0.983860/0.681956 at rate 0.156210\n",
      "epoch:   418 train/test/validatoin error: 0.971442/0.983862/0.681963 at rate 0.155514\n",
      "epoch:   419 train/test/validatoin error: 0.971441/0.983863/0.681971 at rate 0.154822\n",
      "epoch:   420 train/test/validatoin error: 0.971441/0.983865/0.681978 at rate 0.154132\n",
      "epoch:   421 train/test/validatoin error: 0.971440/0.983866/0.681985 at rate 0.153446\n",
      "epoch:   422 train/test/validatoin error: 0.971439/0.983868/0.681992 at rate 0.152763\n",
      "epoch:   423 train/test/validatoin error: 0.971439/0.983870/0.681999 at rate 0.152083\n",
      "epoch:   424 train/test/validatoin error: 0.971438/0.983871/0.682006 at rate 0.151405\n",
      "epoch:   425 train/test/validatoin error: 0.971437/0.983873/0.682013 at rate 0.150731\n",
      "epoch:   426 train/test/validatoin error: 0.971437/0.983874/0.682020 at rate 0.150060\n",
      "epoch:   427 train/test/validatoin error: 0.971436/0.983876/0.682027 at rate 0.149392\n",
      "epoch:   428 train/test/validatoin error: 0.971436/0.983878/0.682034 at rate 0.148727\n",
      "epoch:   429 train/test/validatoin error: 0.971435/0.983879/0.682041 at rate 0.148064\n",
      "epoch:   430 train/test/validatoin error: 0.971434/0.983881/0.682048 at rate 0.147405\n",
      "epoch:   431 train/test/validatoin error: 0.971434/0.983882/0.682055 at rate 0.146749\n",
      "epoch:   432 train/test/validatoin error: 0.971433/0.983884/0.682061 at rate 0.146095\n",
      "epoch:   433 train/test/validatoin error: 0.971433/0.983886/0.682068 at rate 0.145445\n",
      "epoch:   434 train/test/validatoin error: 0.971432/0.983887/0.682075 at rate 0.144797\n",
      "epoch:   435 train/test/validatoin error: 0.971431/0.983889/0.682081 at rate 0.144152\n",
      "epoch:   436 train/test/validatoin error: 0.971431/0.983890/0.682088 at rate 0.143510\n",
      "epoch:   437 train/test/validatoin error: 0.971430/0.983892/0.682095 at rate 0.142871\n",
      "epoch:   438 train/test/validatoin error: 0.971430/0.983893/0.682101 at rate 0.142235\n",
      "epoch:   439 train/test/validatoin error: 0.971429/0.983895/0.682108 at rate 0.141602\n",
      "epoch:   440 train/test/validatoin error: 0.971428/0.983897/0.682114 at rate 0.140971\n",
      "epoch:   441 train/test/validatoin error: 0.971428/0.983898/0.682120 at rate 0.140343\n",
      "epoch:   442 train/test/validatoin error: 0.971427/0.983900/0.682127 at rate 0.139718\n",
      "epoch:   443 train/test/validatoin error: 0.971427/0.983901/0.682133 at rate 0.139096\n",
      "epoch:   444 train/test/validatoin error: 0.971426/0.983903/0.682139 at rate 0.138477\n",
      "epoch:   445 train/test/validatoin error: 0.971426/0.983904/0.682146 at rate 0.137860\n",
      "epoch:   446 train/test/validatoin error: 0.971425/0.983906/0.682152 at rate 0.137246\n",
      "epoch:   447 train/test/validatoin error: 0.971424/0.983907/0.682158 at rate 0.136635\n",
      "epoch:   448 train/test/validatoin error: 0.971424/0.983909/0.682164 at rate 0.136027\n",
      "epoch:   449 train/test/validatoin error: 0.971423/0.983910/0.682170 at rate 0.135421\n",
      "epoch:   450 train/test/validatoin error: 0.971423/0.983912/0.682176 at rate 0.134818\n",
      "epoch:   451 train/test/validatoin error: 0.971422/0.983913/0.682182 at rate 0.134218\n",
      "epoch:   452 train/test/validatoin error: 0.971422/0.983915/0.682188 at rate 0.133620\n",
      "epoch:   453 train/test/validatoin error: 0.971421/0.983916/0.682194 at rate 0.133025\n",
      "epoch:   454 train/test/validatoin error: 0.971421/0.983918/0.682200 at rate 0.132433\n",
      "epoch:   455 train/test/validatoin error: 0.971420/0.983919/0.682206 at rate 0.131843\n",
      "epoch:   456 train/test/validatoin error: 0.971419/0.983921/0.682212 at rate 0.131256\n",
      "epoch:   457 train/test/validatoin error: 0.971419/0.983922/0.682218 at rate 0.130671\n",
      "epoch:   458 train/test/validatoin error: 0.971418/0.983924/0.682224 at rate 0.130090\n",
      "epoch:   459 train/test/validatoin error: 0.971418/0.983925/0.682229 at rate 0.129510\n",
      "epoch:   460 train/test/validatoin error: 0.971417/0.983927/0.682235 at rate 0.128934\n",
      "epoch:   461 train/test/validatoin error: 0.971417/0.983928/0.682241 at rate 0.128359\n",
      "epoch:   462 train/test/validatoin error: 0.971416/0.983929/0.682247 at rate 0.127788\n",
      "epoch:   463 train/test/validatoin error: 0.971416/0.983931/0.682252 at rate 0.127219\n",
      "epoch:   464 train/test/validatoin error: 0.971415/0.983932/0.682258 at rate 0.126652\n",
      "epoch:   465 train/test/validatoin error: 0.971415/0.983934/0.682263 at rate 0.126088\n",
      "epoch:   466 train/test/validatoin error: 0.971414/0.983935/0.682269 at rate 0.125527\n",
      "epoch:   467 train/test/validatoin error: 0.971414/0.983937/0.682275 at rate 0.124968\n",
      "epoch:   468 train/test/validatoin error: 0.971413/0.983938/0.682280 at rate 0.124412\n",
      "epoch:   469 train/test/validatoin error: 0.971413/0.983940/0.682286 at rate 0.123858\n",
      "epoch:   470 train/test/validatoin error: 0.971412/0.983941/0.682291 at rate 0.123306\n",
      "epoch:   471 train/test/validatoin error: 0.971412/0.983942/0.682296 at rate 0.122757\n",
      "epoch:   472 train/test/validatoin error: 0.971411/0.983944/0.682302 at rate 0.122210\n",
      "epoch:   473 train/test/validatoin error: 0.971411/0.983945/0.682307 at rate 0.121666\n",
      "epoch:   474 train/test/validatoin error: 0.971410/0.983947/0.682312 at rate 0.121124\n",
      "epoch:   475 train/test/validatoin error: 0.971410/0.983948/0.682318 at rate 0.120585\n",
      "epoch:   476 train/test/validatoin error: 0.971409/0.983949/0.682323 at rate 0.120048\n",
      "epoch:   477 train/test/validatoin error: 0.971409/0.983951/0.682328 at rate 0.119513\n",
      "epoch:   478 train/test/validatoin error: 0.971408/0.983952/0.682334 at rate 0.118981\n",
      "epoch:   479 train/test/validatoin error: 0.971408/0.983954/0.682339 at rate 0.118451\n",
      "epoch:   480 train/test/validatoin error: 0.971407/0.983955/0.682344 at rate 0.117924\n",
      "epoch:   481 train/test/validatoin error: 0.971407/0.983956/0.682349 at rate 0.117399\n",
      "epoch:   482 train/test/validatoin error: 0.971406/0.983958/0.682354 at rate 0.116876\n",
      "epoch:   483 train/test/validatoin error: 0.971406/0.983959/0.682359 at rate 0.116356\n",
      "epoch:   484 train/test/validatoin error: 0.971405/0.983960/0.682364 at rate 0.115838\n",
      "epoch:   485 train/test/validatoin error: 0.971405/0.983962/0.682369 at rate 0.115322\n",
      "epoch:   486 train/test/validatoin error: 0.971404/0.983963/0.682374 at rate 0.114808\n",
      "epoch:   487 train/test/validatoin error: 0.971404/0.983964/0.682379 at rate 0.114297\n"
     ]
    }
   ],
   "source": [
    "lr = 1.0\n",
    "\n",
    "#train('test', 0.001, 2, from_scratch=True, print_step=50)\n",
    "# train('deep_test', valid_ind=0, from_scratch=True, learn_rate_start=lr, learn_rate_min=lr, learn_rate_base=1.0, \n",
    "#       batch_size=8000, print_step=1) # constant learning rate\n",
    "train('deep_test', valid_ind=2, from_scratch=False, print_step=1, \n",
    "      learn_rate_start=lr, learn_rate_min=0.00005, learn_rate_steps=50, learn_rate_base=0.8, batch_size=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train(root_name='model', learn_rate=0.001, valid_ind=2, \n",
    "#           train_list=range(len(inp_grp)), print_step=5, from_scratch=False,\n",
    "#           threshold=1E-5, maxiter=100000\n",
    "#          ):\n",
    "\n",
    "total_list = range(10)\n",
    "tags = [str(i) for i in range(1, 10)]\n",
    "inds = [total_list[:i] for i in range(1, 10)]\n",
    "\n",
    "del tags[2]\n",
    "del inds[2]\n",
    "\n",
    "for i in range(len(tags)):\n",
    "    tag = tags[i]\n",
    "    ind = inds[i]\n",
    "    train('increment_full_2-%s' % tag, 0.02, 2, ind, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
